# label y-axis as supplied by parameter
scale_y_discrete(labels=ylabels) +
# adhere to style and add labels
theme_bw() +
theme(axis.text.x=element_text(angle=25, hjust=1.0)) +
xlab("Feature") + ylab("Classifier")
return(p)
}
plot_features(featurescores.display, clf.labels) +
ggtitle("Features Selected by SelectKBest Facetted by Feature Scaling (TRUE/FALSE)")
plot_features <- function(t, ylabels) {
# Plot a tile plot with the features on x and the classifiers
# on y - we will facet wrap by the feature scaling criterion
# later on
p <- ggplot(data=t, aes(x=feature, y=clf.factor)) +
geom_tile(aes(fill=score)) +
# put texts over the tiles
geom_text(aes(label=round(as.numeric(score),3))) +
# put symbol for algorithm in the first column
geom_point(aes(color=clf.factor, shape=config.id-2),
x=1, size=4, stroke=2, alpha=0.5) +
# facet wrap by feature scaling (TRUE/FALSE)
facet_wrap(~feature.scaling, nrow=2) +
# make sure algorithm symbols (points) show appropriately
config_scale + clf_scale_guide +
# fill the tiles correctly, first column is reserved
# for algorithm symbol and should be all "NA", therefore white
scale_fill_gradient("Score", low="lightyellow",
high="green3", na.value="white") +
# remove the first label from the x-axis
scale_x_discrete(labels=c("",levels(t$feature)
[2:length(levels(t$feature))])) +
# label y-axis as supplied by parameter
scale_y_discrete(labels=ylabels) +
# adhere to style and add labels
theme_bw() +
theme(axis.text.x=element_text(angle=25, hjust=1.0)) +
xlab("Feature") + ylab("Classifier")
return(p)
}
plot_features(featurescores.display, clf.labels) +
ggtitle("Features Selected by SelectKBest Facetted by Feature Scaling (TRUE/FALSE)")
t$config.id
clf.each.configs %>%
subset(feature.selection==TRUE) %>%
select(config.id, feature.scaling)
clf.each.configs
clf.each.configs
str(clf.each.configs)
clf.each.configs %>%
subset(feature.selection==TRUE) %>%
select(config.id, feature.scaling)
clf.each.configs
value<-Woman
value<-"Woman"
value[value=="Woman"]
value[value=="Man"]
value=T
value[value==T]
value[value==F]
feature.scaling_labeller <- function(var, value){
value <- as.character(value)
if (var=="feature.scaling") {
value[value==T] <- "feature scaling"
value[value==F] <- "no feature scaling"
}
return(value)
}
ggplot(data=t, aes(x=feature, y=clf.factor)) +
geom_tile(aes(fill=score)) +
# put texts over the tiles
geom_text(aes(label=round(as.numeric(score),3))) +
# put symbol for algorithm in the first column
geom_point(aes(color=clf.factor, shape=config.id),
x=1, size=4, stroke=2, alpha=0.5) +
# facet wrap by feature scaling (TRUE/FALSE)
facet_wrap(~feature.scaling, nrow=2,
labeller=feature.scaling_labeller) +
# make sure algorithm symbols (points) show appropriately
config_scale + clf_scale_guide +
# fill the tiles correctly, first column is reserved
# for algorithm symbol and should be all "NA", therefore white
scale_fill_gradient("Score", low="lightyellow",
high="green3", na.value="white") +
# remove the first label from the x-axis
scale_x_discrete(labels=c("",levels(t$feature)
[2:length(levels(t$feature))])) +
# label y-axis as supplied by parameter
scale_y_discrete(labels=ylabels) +
# adhere to style and add labels
theme_bw() +
theme(axis.text.x=element_text(angle=25, hjust=1.0)) +
xlab("Feature") + ylab("Classifier")
ggplot(data=t, aes(x=feature, y=clf.factor)) +
geom_tile(aes(fill=score)) +
# put texts over the tiles
geom_text(aes(label=round(as.numeric(score),3))) +
# put symbol for algorithm in the first column
geom_point(aes(color=clf.factor, shape=config.id),
x=1, size=4, stroke=2, alpha=0.5) +
# facet wrap by feature scaling (TRUE/FALSE)
facet_grid(feature.scaling~., nrow=2,
labeller=feature.scaling_labeller) +
# make sure algorithm symbols (points) show appropriately
config_scale + clf_scale_guide +
# fill the tiles correctly, first column is reserved
# for algorithm symbol and should be all "NA", therefore white
scale_fill_gradient("Score", low="lightyellow",
high="green3", na.value="white") +
# remove the first label from the x-axis
scale_x_discrete(labels=c("",levels(t$feature)
[2:length(levels(t$feature))])) +
# label y-axis as supplied by parameter
scale_y_discrete(labels=ylabels) +
# adhere to style and add labels
theme_bw() +
theme(axis.text.x=element_text(angle=25, hjust=1.0)) +
xlab("Feature") + ylab("Classifier")
ggplot(data=t, aes(x=feature, y=clf.factor)) +
geom_tile(aes(fill=score)) +
# put texts over the tiles
geom_text(aes(label=round(as.numeric(score),3))) +
# put symbol for algorithm in the first column
geom_point(aes(color=clf.factor, shape=config.id),
x=1, size=4, stroke=2, alpha=0.5) +
# facet wrap by feature scaling (TRUE/FALSE)
facet_grid(feature.scaling~.,
labeller=feature.scaling_labeller) +
# make sure algorithm symbols (points) show appropriately
config_scale + clf_scale_guide +
# fill the tiles correctly, first column is reserved
# for algorithm symbol and should be all "NA", therefore white
scale_fill_gradient("Score", low="lightyellow",
high="green3", na.value="white") +
# remove the first label from the x-axis
scale_x_discrete(labels=c("",levels(t$feature)
[2:length(levels(t$feature))])) +
# label y-axis as supplied by parameter
scale_y_discrete(labels=ylabels) +
# adhere to style and add labels
theme_bw() +
theme(axis.text.x=element_text(angle=25, hjust=1.0)) +
xlab("Feature") + ylab("Classifier")
setwd("h:/Dokumente/GitHub/DAND_5_MachineLearningEnronData/final_project")
source(file="batch_analyzer.R")
config_scale <- scale_shape_manual(
name="Configuration",
values=c("0"=0,"1"=1,"2"=15,"3"=16,"4"=63),
label=c("0"="no scaling,\nno feature selection",
"1"="scaling,\nno feature selection",
"2"="no scaling,\nfeature selection",
"3"="scaling,\nfeature selection",
"4"="indifferent"),
na.value=63
)
plot_table(bestest.ranked, FALSE) +
geom_hline(y=c(1.5,2.5,3.5,4.5,5.5,6.5)) +
ggtitle("Best configurations per classifier ordered by performance")
tt<-seq(1:100)
tt<-seq(1:50)
tt$s <- seq(1:50)
tt
ggplot(data=tt,aes(x=s,shape=s)) + geom_point()
gg$s <- seq(1:50)
gg <- df()
?df
gg <- data.frame()
gg$s <- seq(1:50)
gg
?data.frame
LETTERS
gg <- data.frame(s=seq(1:50))
gg
ggplot(aes(y=s, shape=s), data=gg) + geom_point()
ggplot(aes(y=s, shape=as.factor(s)), data=gg) + geom_point()
gg
?scale_shape_manual
?scale_shape
setwd("h:/Dokumente/GitHub/DAND_5_MachineLearningEnronData/final_project")
source(file="batch_analyzer.R")
View(batch)
setwd("h:/Dokumente/GitHub/DAND_5_MachineLearningEnronData/final_project")
source(file="batch_analyzer.R")
View(clf.all.configs)
View(batch)
all <- clf.all.configs %>%
left_join(batch, by=c("clf.id","feature.scaling","feature.selection"))
all$gt.0.3 = (all$precision > 0.3 & all$recall > 0.3)
best.ranked <- all %>%
group_by(clf.id) %>%
summarise(f1=max(f1, na.rm=T)) %>%
left_join(all, by=c("clf.id","f1")) %>%
arrange(desc(gt.0.3), desc(f1), runtime)
clf.levels <- unique(best.ranked$clf.name)
clf.labels <- gsub("^(.{,15})([^ ]*) (.*)$","\\1\\2\n\\3", clf.levels)
best.ranked$clf.factor <- factor(best.ranked$clf.name, levels=clf.levels)
all$clf.factor <- factor(all$clf.name, levels=clf.levels)
clf.ids$clf.factor <- factor(clf.ids$clf.name, levels=clf.levels)
all$clf.factor <- factor(all$clf.name, levels=clf.levels)
all.ranked <- all %>% arrange(clf.factor, desc(f1), runtime)
bestest.ranked <- best.ranked %>%
group_by(clf.id, f1, clf.name, precision, recall, accuracy, gt.0.3,
clf.factor) %>%
summarize(feature.scaling=merge_vector(feature.scaling),
feature.selection=merge_vector(feature.selection),
config.id=merge_vector(config.id)) %>%
ungroup() %>%
arrange(clf.factor)
bestest.ranked$config.id = as.factor(bestest.ranked$config.id)
featurescores.file = "poi_id_featurescores.csv"
featurescores.file = "poi_id_featurescores.csv"
featurescores.col.names <- c("feature.scaling", "clf.id", "feature", "score")
featurescores.col.type <- c("factor", "numeric", "character", "numeric")
featurescores <- read.csv(featurescores.file, header=FALSE,
col.names=featurescores.col.names,
colClasses=featurescores.col.type)
featurescores.configs <- clf.each.configs %>%
subset(feature.selection==TRUE) %>%
select(config.id, feature.scaling)
featurescores.ranked <- featurescores %>%
left_join(clf.ids, by=c("clf.id")) %>%
left_join(featurescores.configs, by=c("feature.scaling"))
featurescores.means <- featurescores %>%
spread(feature, score) %>%
select(-feature.scaling, -clf.id) %>%
summarise_each(funs(mean))
featurescores.means <- featurescores.means %>%
gather("feature","meanscore",1:length(names(featurescores.means))) %>%
arrange(desc(meanscore))
featurescores.levels <-
c("clf.id", unique(as.character(featurescores.means$feature)))
featurescores.ranked$feature <-
factor(as.character(featurescores.ranked$feature),
levels=featurescores.levels)
featurescores.labels <- merge(clf.ids, featurescores.configs) %>%
select(feature.scaling, clf.id, clf.name, clf.factor, config.id) %>%
mutate(feature=factor("clf.id",levels=featurescores.levels),
score=as.numeric(NA))
featurescores.display <- featurescores.ranked %>%
union(featurescores.labels)
metrics_scale <- scale_fill_gradientn(
name="Performance", na.value="white",
colours=c("grey","lightgrey","lightgreen","darkgreen"),
limits=c(0,1), breaks=c(0,0.3,1.0),
values=c(
rescale(1:201,to=c(0.0,0.3)),
rescale(1:201,to=c(0.3,1.0))
)
)
metrics_scale <- scale_fill_gradientn(
name="Performance", na.value="white",
colours=c("grey","lightgrey","lightgreen","darkgreen"),
limits=c(0,1), breaks=c(0,0.3,1.0),
values=c(
rescale(1:201,to=c(0.0,0.3)),
rescale(1:201,to=c(0.3,1.0))
)
)
# ggplot gradient for displaying algorithm configuration
config_scale <- scale_shape_manual(
name="Configuration",
values=c("0"=0,"1"=1,"2"=2,"3"=15,"4"=16,"5"=17,"6"=63),
label=c("0"="no scaling,\nno feature selection",
"1"="scaling,\nno feature selection",
"2"="PCA,\nno feature selection",
"3"="no scaling,\nfeature selection",
"4"="scaling,\nfeature selection",
"5"="PCA,\nno feature selection",
"6"="indifferent"),
na.value=63
)
# ggplot colors for different classifiers; as color without guide
clf_scale_noguide <- scale_color_brewer(
type="qual", palette="Dark2", guide=FALSE,
breaks=clf.levels,
labels=clf.labels
)
# ggplot colors for different classifiers; as color with guide
clf_scale_guide <- scale_color_brewer(
name="Classifier",
type="qual", palette="Dark2",
breaks=clf.levels,
labels=clf.labels
)
# ggplot colors for different classifiers; as fill with guide
clf_scale_fill <- scale_fill_brewer(
name="Classifier",
type="qual", palette="Dark2",
breaks=clf.levels,
labels=clf.labels
)
# labeller for facet wrap of "feature selection"
feature.scaling_labeller <- function(var, value){
value <- as.character(value)
if (var=="feature.scaling") {
value[value==T] <- "feature scaling"
value[value==F] <- "no feature scaling"
}
return(value)
}
setwd("h:/Dokumente/GitHub/DAND_5_MachineLearningEnronData/final_project")
source(file="batch_analyzer.R")
plot_features(featurescores.display, clf.labels) +
ggtitle("Features Selected by SelectKBest")
plot_table(all.ranked, TRUE) +
geom_hline(y=c(4.5,8.5,12.5,16.5,20.5,24.5)) +
ggtitle("All cross-examined configurations ordered by performance")
plot_table(all.ranked, TRUE) +
geom_hline(y=c(6.5,12.5,18.5,24.5,30.5,36.5)) +
ggtitle("All cross-examined configurations ordered by performance")
plot_table(bestest.ranked, FALSE) +
geom_hline(y=c(1.5,2.5,3.5,4.5,5.5,6.5)) +
ggtitle("Best configurations per classifier ordered by performance")
plot_performance(all.ranked) +
ggtitle("Precision & Recall of Classifiers")
plot_runtime(all.ranked) +
ggtitle("Runtime of Classifiers for 1000 Outputs")
setwd("h:/Dokumente/GitHub/DAND_5_MachineLearningEnronData/final_project")
source(file="batch_analyzer.R")
plot_runtime(all.ranked) +
ggtitle("Runtime of Classifiers for 1000 Outputs")
setwd("h:/Dokumente/GitHub/DAND_5_MachineLearningEnronData/final_project")
source(file="batch_analyzer.R")
plot_runtime(all.ranked) +
ggtitle("Runtime of Classifiers for 1000 Outputs")
setwd("h:/Dokumente/GitHub/DAND_5_MachineLearningEnronData/final_project")
source(file="batch_analyzer.R")
plot_runtime(all.ranked) +
ggtitle("Runtime of Classifiers for 1000 Outputs")
str(bestest.ranked$config.id)
str(all.ranked$config.id)
levels(bestest.ranked$config.id)
levels(all.ranked$config.id)
plot_table(bestest.ranked, FALSE) +
geom_hline(y=c(1.5,2.5,3.5,4.5,5.5,6.5)) +
ggtitle("Best configurations per classifier ordered by performance")
setwd("h:/Dokumente/GitHub/DAND_5_MachineLearningEnronData/final_project")
source(file="batch_analyzer.R")
plot_table(bestest.ranked, FALSE) +
geom_hline(y=c(1.5,2.5,3.5,4.5,5.5,6.5)) +
ggtitle("Best configurations per classifier ordered by performance")
config_scale <- scale_shape_manual(
name="Configuration",
values=c("0"=0,"1"=1,"2"=2,"3"=15,"4"=16,"5"=17,"6"=63),
label=c("0"="no feature scaling,\nmanual feature selection",
"1"="MinMax feature scaling,\nmanual feature selection",
"2"="PCA,\nmanual feature selection",
"3"="no feature scaling,\nautomatic feature selection",
"4"="MinMax feature scaling,\nautomatic feature selection",
"5"="PCA,\nautomatic feature selection",
"6"="indifferent"),
na.value=63
)
plot_table(bestest.ranked, FALSE) +
geom_hline(y=c(1.5,2.5,3.5,4.5,5.5,6.5)) +
ggtitle("Best configurations per classifier ordered by performance")
config_scale <- scale_shape_manual(
name="Configuration",
values=c("0"=0,"1"=1,"2"=2,"3"=15,"4"=16,"5"=17,"6"=63),
label=c("0"="no feature scaling,\nmanual feature selection",
"1"="MinMax feature scaling,\nmanual feature selection",
"2"="PCA,\nmanual feature selection",
"3"="no feature scaling,\nautomatic feature selection",
"4"="MinMax feature scaling,\nautomatic feature selection",
"5"="PCA,\nautomatic feature selection",
"6"="indifferent"),
na.value=63
)
config_scale <- scale_shape_manual(
name="Configuration",
values=c("0"=0,"1"=1,"2"=2,"3"=15,"4"=16,"5"=17,"6"=63),
label=c("0"="no feature scaling,\nmanual feature selection",
"1"="MinMax feature scaling,\nmanual feature selection",
"2"="PCA,\nmanual feature selection",
"3"="no feature scaling,\nautomatic feature selection",
"4"="MinMax feature scaling,\nautomatic feature selection",
"5"="PCA,\nautomatic feature selection",
"6"="indifferent"),
na.value=63,
na.label="indifferent"
)
config_scale <- scale_shape_manual(
name="Configuration",
values=c("0"=0,"1"=1,"2"=2,"3"=15,"4"=16,"5"=17,"6"=63),
label=c("0"="no feature scaling,\nmanual feature selection",
"1"="MinMax feature scaling,\nmanual feature selection",
"2"="PCA,\nmanual feature selection",
"3"="no feature scaling,\nautomatic feature selection",
"4"="MinMax feature scaling,\nautomatic feature selection",
"5"="PCA,\nautomatic feature selection",
"6"="indifferent",
"NA"="indifferent"),
na.value=63,
na.label="indifferent"
)
config_scale <- scale_shape_manual(
name="Configuration",
values=c("0"=0,"1"=1,"2"=2,"3"=15,"4"=16,"5"=17,"6"=63),
label=c("0"="no feature scaling,\nmanual feature selection",
"1"="MinMax feature scaling,\nmanual feature selection",
"2"="PCA,\nmanual feature selection",
"3"="no feature scaling,\nautomatic feature selection",
"4"="MinMax feature scaling,\nautomatic feature selection",
"5"="PCA,\nautomatic feature selection",
"6"="indifferent",
"NA"="indifferent"),
na.value=63
)
plot_table(bestest.ranked, FALSE) +
geom_hline(y=c(1.5,2.5,3.5,4.5,5.5,6.5)) +
ggtitle("Best configurations per classifier ordered by performance")
?scale_shape
config_scale <- scale_shape_manual(
name="Configuration",
values=c("0"=0,"1"=1,"2"=2,"3"=15,"4"=16,"5"=17,"6"=63),
label=c("0"="no feature scaling,\nmanual feature selection",
"1"="MinMax feature scaling,\nmanual feature selection",
"2"="PCA,\nmanual feature selection",
"3"="no feature scaling,\nautomatic feature selection",
"4"="MinMax feature scaling,\nautomatic feature selection",
"5"="PCA,\nautomatic feature selection",
"6"="indifferent",
"NA"="indifferent"),
na.value=NA
)
plot_table(bestest.ranked, FALSE) +
geom_hline(y=c(1.5,2.5,3.5,4.5,5.5,6.5)) +
ggtitle("Best configurations per classifier ordered by performance")
?scale_shape
c("0"="no feature scaling,\nmanual feature selection",
"1"="MinMax feature scaling,\nmanual feature selection",
"2"="PCA,\nmanual feature selection",
"3"="no feature scaling,\nautomatic feature selection",
"4"="MinMax feature scaling,\nautomatic feature selection",
"5"="PCA,\nautomatic feature selection",
"6"="indifferent",
NA="indifferent")
?fill.na
??fill.na
na.fill
library(zoo)
na.fill(c(NA,NA),"1")
setwd("h:/Dokumente/GitHub/DAND_5_MachineLearningEnronData/final_project")
source(file="batch_analyzer.R")
plot_table(bestest.ranked, FALSE) +
geom_hline(y=c(1.5,2.5,3.5,4.5,5.5,6.5)) +
ggtitle("Best configurations per classifier ordered by performance")
na.fill(bestest.ranked$config.id, "-1")
na.fill(as.numeric(bestest.ranked$config.id), "-1")
as.factor(na.fill(as.numeric(bestest.ranked$config.id), "-1"))
setwd("h:/Dokumente/GitHub/DAND_5_MachineLearningEnronData/final_project")
source(file="batch_analyzer.R")
plot_table(bestest.ranked, FALSE) +
geom_hline(y=c(1.5,2.5,3.5,4.5,5.5,6.5)) +
ggtitle("Best configurations per classifier ordered by performance")
na.fill(as.numeric(bestest.ranked$config.id))
na.fill(as.numeric(bestest.ranked$config.id), "-1")
na.fill(as.numeric(bestest.ranked$config.id), -1)
setwd("h:/Dokumente/GitHub/DAND_5_MachineLearningEnronData/final_project")
source(file="batch_analyzer.R")
plot_table(bestest.ranked, FALSE) +
geom_hline(y=c(1.5,2.5,3.5,4.5,5.5,6.5)) +
ggtitle("Best configurations per classifier ordered by performance")
factor(
na.fill(as.numeric(bestest.ranked$config.id), -1),
c(levels(bestest.ranked$config.id),"-1"))
)
bestest.ranked$config.id
as.numeric(bestest.ranked$config.id)
as.character(bestest.ranked$config.id)
factor(
na.fill(as.character(bestest.ranked$config.id), "-1"),
c(levels(bestest.ranked$config.id),"-1"))
)
factor(
na.fill(as.character(bestest.ranked$config.id), "-1"),
c(levels(bestest.ranked$config.id),"-1"))
bestest.ranked$config.id
na.fill(as.character(bestest.ranked$config.id), "-1")
as.character(bestest.ranked$config.id)
na.fill(as.character(bestest.ranked$config.id),"-1")
na.fill(c(NA,NA),"-1")
as.character(bestest.ranked$config.id)[1]
as.character(bestest.ranked$config.id)[1]==NA
as.character(bestest.ranked$config.id)[1] is NA
is.na(as.character(bestest.ranked$config.id))
?na.fill
z <- zoo(c(NA, 2, NA, 1, 4, 5, 2, NA))
na.fill(z, "extend")
na.fill(z, c("extend", NA))
na.fill(z, "1")
na.fill(z, 815)
z
na.fill(c(NA,NA),"-1")
bestest.ranked$config.id
as.character(bestest.ranked$config.id)
z <- as.character(bestest.ranked$config.id)
na.fill(z, "-1")
na.fill(z, -1)
na.fill(z, list(-1)
)
na.fill(z, c(-1))
na.fill(z, c("-1"))
na.fill(z, c("extend","-1"))
z
is.na(z)
z[is.na(z)]
setwd("h:/Dokumente/GitHub/DAND_5_MachineLearningEnronData/final_project")
source(file="batch_analyzer.R")
plot_table(bestest.ranked, FALSE) +
geom_hline(y=c(1.5,2.5,3.5,4.5,5.5,6.5)) +
ggtitle("Best configurations per classifier ordered by performance")
